# 大文件排序问题

## 1. 数字排序问题

**题目**：有一个大文件，里面记录了若干数字，把这些数字进行排序。文件大小远大于内存大小。
**思路**：内存极少的情况下，利用分治策略，利用外存保存中间结果，再用多路归并来排序。

（1）按可用内存的大小，把外存上含有n个记录的文件分成若干个长度为L的子文件，把这些子文件依次读入内存，并利用有效的内部排序方法对它们进行排序，再将排序后得到的有序子文件重新写入外存；

（2）对这些有序子文件逐趟归并，使其逐渐由小到大，直至得到整个有序文件为止。

**下面的思路和上面的思路一样**：

设文件共有m*n条记录， 内存中每次可以对m条记录进行排序

- 则排序过程分两步：

  1. 第一步：从磁盘中读入m条记录到内存； 在内存排序； 将排好序的数据写入新文件；
    重复上述过程n次 共生成n个新文件

  2. 第二步：分配一个文件指针数组 包含n个文件指针，分别指向n个新文件（这里没有上一个方法的思路好，但是便于理解）；
    分配一个整数数组 大小为n 分别顺序读取各个文件的数据
    分配一个布尔数组 大小为n 指示各个文件是否读完
    将读入的整数数组中最小的值写入外存 并继续往后读取对应的文件 然后重复这一步 直到所有的文件都读完

  这种算法思想常用于大文件排序，文件大小超出内存容量，可以每次读取内存容量的数据进行内存排序，然后进行归并

  采用类似思想还可以解决很多海量数据处理的问题，当内存容量不足以一次处理时，通常都是先将大文件分为小文件，然后分而治之

**参考**：[多路归并 外排序 大文件排序 海量数据处理](https://blog.csdn.net/longzuo/article/details/46409249)

---

## 2. 字符串重复次数问题

**问题**：有一个1.3GB的文件(共一亿行)，里面每一行都是一个字符串，请在文件中找出重复次数最多的字符串。

**基本思想**：迭代读大文件，把大文件拆分成多个小文件；最后再归并这些小文件。

**拆分的规则**：

  迭代读大文件，内存中维护一个字典，key是字符串，value是该字符串出现的次数；

当字典维护的字符串种类达到10000（可自定义）的时候，把该字典按照key从小到大排序，然后写入小文件，每行是 key\tvalue；

然后清空字典，继续往下读，直到大文件读完。

**归并的规则**：

  首先获取全部小文件的文件描述符，然后各自读出第一行（即每个小文件字符串ascii值最小的字符串），进行比较。

找出ascii值最小的字符串，如果有重复的，这把各自出现的次数累加起来，然后把当前字符串和总次数存储到内存中的一个列表。

然后把最小字符串所在的文件的读指针向下移，即从对应小文件里再读出一行进行下一轮比较。

当内存中的列表个数达到10000时，则一次性把该列表内容写到一个最终文件里存储到硬盘上。同时清空列表，进行之后的比较。

一直到读完全部的小文件，那么最后得到的最终文件就是一个按照字符串ascii值升序排序的大的文件，每一行的内容就是 字符串\t重复次数，

最后迭代去读这个最终文件，找出重复次数最多的即可。

**参考**：

- [大文件排序问题](https://blog.csdn.net/okiwilldoit/article/details/80626508)
- [大文件排序/外存排序问题](https://www.cnblogs.com/standby/p/9780910.html)

---

## 3. 大数据中找中位数

**问题**：在一个大文件中有100亿个32位整数，乱序排列，要求找出中位数；内存限制为512M；请写出算法设计思路；

**基本分析**：

（1）中位数的定义：一个给定排序好的序列，奇数个的话，我们就取中间的一个；偶数个的话，我们一般取中间两个数的平均值；因此对于本题，我们需得到中间的第50亿和第50亿+1这两个数；

（2）首先512M的内存，如果都来装这个32位整数的话，可以存储2^(9+10+10)/4=2^27（134217728）个数（1亿左右的数）；常规的内部排序肯定是不行了，因为内存不够；而且是乱序排列，所以二分查找不行；所以本题的时间复杂度最少为O(n);

（3）由于内存是512M，可存储1亿个数；那么我们先把100亿个数分成100组；使用512M高内存可装载1亿个数，装载100次；

**算法思路**：

（1）我们要划分映射区域，一个有符号的32位整数的取值范围是[-2^31, 2^31-1]，总共有4294967296个取值，因此我们将它划分成100000组，即43000个数映射到一个组，将a1的区间[-2^31，-2^31+43000)，a2的区间[-2^31+43000，-2^31+86000)......一直到a100000的区间；（这是组数与项数的一个平衡问题）；

（2.1）我们首先装载第一个1亿个数，遍历这些数，比较大小，看他落入a1至a100000的哪个区间，落入的对应区间统计计数增1；这次是对这里面的数区间的组映射；

（2.2）重复步骤（2.1），装载100次，这样我们就得到了a1至a100000的区间统计计数的取值；

（2.3）内存分析：1亿个数用来装载，100000个区间统计计数耗费400000个字节，足够使用；剩余内存（128M-1亿-100000）*4B;

（3.1）使用sum依次累加a1至a100000的区间统计计数，直到累加某区间ai后sum大于50亿了；那么第50亿个数就在该区间中，用sum减去该区间ai的统计数的到first；即前面的区间统计总数位置为第first个（其中first < 50亿）;

（3.2）那么我就在ai区间找到第50亿-first个数，或第50亿-first+1个数（第50亿-first+1个数这个数可能在ai后面的区间，但是概率很小，但是找到的原理类似）；

（3.3）内存分析：每一个区间分割比较要花费100000个区间比较数，耗费400000个字节，足够使用；剩余内存（128M-1亿-100000-100000-2）*4B;

（4.1）再次遍历这100亿个数，还是每组1亿个数，一共100组；对于若在ai区间的43000个数的每一个都开一个统计计数器 ，跟上面类似，这次是对这里面的数单个映射；

（4.2）同样使用sum依次累加这1至43000的的统计计数，直到累加某区间后sum大于50亿-first；那么我们可以得到第（50亿-first）个数就在对应的位置；而且第（50亿-first+1）个数位置也有可能在，或在下一个统计计数大于0的位置；当然也有可能不在ai区间；（但原理类似）；

（4.3）得到了第（50亿-first）个数值；而且第（50亿-first+1）个数值，可算出中位数了；

（4.4）内存分析：上述的100000个比较数，此时我们只需要两个比较数；100000个区间统计计数全部释放掉，但增加了43000位置统计计数；剩余内存（128M-1亿-43000-2-2）*4B；还是足够使用的；

（5）总共遍历两遍100亿数据；

**参考**：[【原理思路】大数据中找中位数（腾讯面试题）](https://blog.csdn.net/sykpour/article/details/26480217?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

---
