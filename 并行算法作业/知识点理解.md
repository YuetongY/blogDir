# 知识点理解

## MPI

全称是 message passing interface ，即信息传递接口，是用于跨节点通讯的基础软件环境。它提供让相关进程之间进行通信，同步等操作的API

一个 MPI 程序包含若干个进程。每个 mpi 进程都运行一份相同的代码，进程的行为由通讯域(communication world)和该通讯域下的 id(rank id)所决定。

**参考**：[MPI初探（原理与认识）](https://blog.csdn.net/u012675539/article/details/43266601)

---

## 并行性能分析

第一个性能当然是速度，还有两个：

    - 延时：完成指定工作所需要的时间

    - 吞吐率：单位时间内完成的工作量

**参考**：

- [并行计算性能分析](https://www.cnblogs.com/zhangchaoyang/articles/2311630.html)

- [并行程序的性能分析](http://prof.ict.ac.cn/DComputing/uploads/2012/DC_5_3%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90.pdf)

---

## MPI 安装

验证是否安装成功可以运行第二个链接中的 `mpirun -np 10 ./examples/cpi` 命令（需要进入 `mpich-3.3.1` 文件夹中执行）

**参考**：

- [我的并行计算之路（一）Ubuntu 16.04下的MPI安装](https://blog.csdn.net/qq_30239975/article/details/77703321)

- [Linux系统（Ubuntu）下MPI的安装与配置](https://zhuanlan.zhihu.com/p/25623484)

---

## function

- MPI_Barrier：用于一个通信子中所有进程的同步，调用函数时进程将处于等待状态，直到通信子中所有进程 都调用了该函数后才继续执行。

    [MPI聚合通信之MPI_Barrier函数](https://blog.csdn.net/u014247371/article/details/26958469)

- MPI_Scatter函数：通过根进程向同一个通信域中的所有进程发送数据，将数据发送缓冲区的数据分割成长度相等的段，然后分段发送数据给每个进程，如果每段包含N个数据，则向进程i发送的段为[send[i*N],int[i*N+N])
    函数参数：MPI_Scatter(待发送数据缓冲区地址，数据个数，数据类型，接收缓冲区地址，数据个数，数据类型，发送消息的进程的标识，通信域） MPI_Scatter(send, N, MPI_INT,recv, N, MPI_INT, 0, MPI_COMM_WORLD);

    [MPI散播(MPI_Scatter)](https://blog.csdn.net/ZfengxingJ/article/details/69056051)

- MPI_Init(…);MPI_Comm_size(…);MPI_Comm_rank(…);MPI_Send(…);MPI_Recv(…);MPI_Finalize();

    [MPI编程入门详解](https://www.jianshu.com/p/2fd31665e816)

- MPI_Wtime()

    [MPI 计时器函数 MPI_Wtime()](https://www.cnblogs.com/cuancuancuanhao/p/8444445.html)

- MPI_Gather函数

    [MPI聚合通信之MPI_Gather函数](https://blog.csdn.net/u014247371/article/details/26965185)
