# <center>使用卷积神经网络进行文本分类</center>

摘要
我们使用卷积神经网络(CNN)进行了一系列的实验，这些实验是在预先训练好的词向量上进行的，目的是对文本进行分类。我们证明了一个带有少量的超参数和静态向量的CNN可以在多个基准测试中取得优异的结果。通过微调参数，学习特定于不同文本的向量，可以进一步提高分类性能。本文讨论的CNN模型提高了4种文本的分类效果，共7种文本。包括情感分类和问题分类。
关键词：卷积神经网络、词向量、分类
1	Introduction
近年来，深度学习模型在计算机视觉(Krizhevsky et al.， 2012)和语音识别(Graves et al.， 2013)方面取得了显著的成果。在自然语言处理领域，深度学习方法的大部分工作都涉及到通过神经语言模型学习单词向量表示(Bengio等人，2003;Yih等，2011;Mikolov等，2013)，并在学习的词向量上进行分类(Collobert等，2011)。单词向量，其中单词通过一个隐藏层从稀疏的1-of-V编码投射到一个低维向量空间，本质上是特征提取器，在其维度上对单词的语义特征进行编码。在如此密集的表示中，语义相近的词在低维向量空间中也同样是相近的。
卷积神经网络(CNN)利用具有卷积滤波器的层应用于局部特征(LeCun et al.， 1998)。CNN模型最初是为计算机视觉而发明的，后来被证明对NLP是有效的，在语义解析(Yih et al.， 2014)、搜索查询检索(Shen et al.， 2014)、句子建模(Kalch-brenner et al.， 2014)等传统NLP任务中取得了优异的效果(Collobert et al.， 2011)。
在当前的工作中，我们训练了一个简单的CNN模型，它对词向量进行一层卷积操作。词向量是Mikolov等人(2013)通过一个非监督神经语言模型在谷歌新闻1000亿字上训练出来的，可以公开获取。我们一开始让词向量保持静态，只学习模型的其他参数。尽管很少调整超参数，但这个简单的模型在多个基准测试中都取得了很好的效果，这表明预先训练的词向量是“通用的”特征提取，可以用于各种分类任务。通过微调词向量学习不同的分类任务，可以进一步提高分类的结果。
我们的工作在哲学上与Razavian et al.(2014)相似，Razavian et al.(2014)的研究表明，对于图像分类，从经过预处理的深度学习模型中获得的特征提取器在大量任务中表现良好。
2 Model
图1所示的模型体系结构是Collobert et al.(2011)CNN体系结构的一个略微变体。

设为句子中第i个词对应的k维词向量。那么句子n(如果文本长度不满足规定长度，就对文本做填充0处理)的长度就可以表示为：
                         (1)
(1)式中是指连接操作符。目的是让单词连接成。是卷积滤波器的大小，其中h代表的是单词个数，也就是列长度。经过运算从列窗口获得数据集的一个新特征。表达式如：
                           
(2)中，是一个函数偏置项，代表激活函数，该模型中具体指的是relu函数。这个式子会用来计算文本中所有满足条件的列窗口{},并产生一个一维数组，这个数组代表所获得的特征：
　                           (3)
接下来会对所获得的数组进行池化操作。该操作会将数组中具有最高价值的数值取出来作为最终的特征。通过以上步骤，模型获得了若干个特征。将这些同全连接层进行连接，获得对软件需求数据分类的预测值。
